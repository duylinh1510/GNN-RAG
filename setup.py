#!/usr/bin/env python3
"""
Setup script for Text2Cypher RAG Demo
Kiá»ƒm tra vÃ  cÃ i Ä‘áº·t cÃ¡c dependencies cáº§n thiáº¿t
"""

import subprocess
import sys
import os

def run_command(command, description=""):
    """Cháº¡y command vÃ  hiá»ƒn thá»‹ káº¿t quáº£"""
    print(f"ğŸ”„ {description}")
    try:
        result = subprocess.run(command, shell=True, capture_output=True, text=True)
        if result.returncode == 0:
            print(f"âœ… {description} - ThÃ nh cÃ´ng")
            return True
        else:
            print(f"âŒ {description} - Lá»—i: {result.stderr}")
            return False
    except Exception as e:
        print(f"âŒ {description} - Exception: {str(e)}")
        return False

def check_ollama():
    """Kiá»ƒm tra Ollama Ä‘Ã£ Ä‘Æ°á»£c cÃ i Ä‘áº·t chÆ°a"""
    print("\nğŸ“‹ Kiá»ƒm tra Ollama...")
    return run_command("ollama --version", "Kiá»ƒm tra Ollama Ä‘Ã£ cÃ i Ä‘áº·t")

def check_ollama_running():
    """Kiá»ƒm tra Ollama cÃ³ Ä‘ang cháº¡y khÃ´ng"""
    print("\nğŸ“‹ Kiá»ƒm tra Ollama Ä‘ang cháº¡y...")
    return run_command("ollama list", "Kiá»ƒm tra Ollama service")

def install_model():
    """CÃ i Ä‘áº·t mÃ´ hÃ¬nh llama3.2"""
    print("\nğŸ“‹ CÃ i Ä‘áº·t mÃ´ hÃ¬nh llama3.2...")
    return run_command("ollama pull llama3.2", "CÃ i Ä‘áº·t llama3.2 model")

def install_python_deps():
    """CÃ i Ä‘áº·t Python dependencies"""
    print("\nğŸ“‹ CÃ i Ä‘áº·t Python dependencies...")
    return run_command("pip install -r requirements.txt", "CÃ i Ä‘áº·t Python packages")

def main():
    print("ğŸš€ Text2Cypher RAG Demo Setup")
    print("=" * 40)
    
    # Kiá»ƒm tra file requirements.txt
    if not os.path.exists("requirements.txt"):
        print("âŒ KhÃ´ng tÃ¬m tháº¥y requirements.txt")
        sys.exit(1)
    
    # Kiá»ƒm tra schema.txt
    if not os.path.exists("schema.txt"):
        print("âŒ KhÃ´ng tÃ¬m tháº¥y schema.txt")
        sys.exit(1)
    
    success = True
    
    # 1. Kiá»ƒm tra Ollama
    if not check_ollama():
        print("\nğŸ”§ HÆ°á»›ng dáº«n cÃ i Ä‘áº·t Ollama:")
        print("   Windows: winget install Ollama.Ollama")
        print("   Hoáº·c táº£i tá»«: https://ollama.ai/download")
        success = False
    
    # 2. CÃ i Ä‘áº·t Python dependencies
    if not install_python_deps():
        success = False
    
    # 3. Kiá»ƒm tra Ollama Ä‘ang cháº¡y
    if not check_ollama_running():
        print("\nğŸ”§ Khá»Ÿi Ä‘á»™ng Ollama:")
        print("   Cháº¡y lá»‡nh: ollama serve")
        print("   Sau Ä‘Ã³ cháº¡y láº¡i script nÃ y")
        success = False
    else:
        # 4. CÃ i Ä‘áº·t mÃ´ hÃ¬nh llama3.2
        if not install_model():
            print("\nğŸ”§ CÃ i Ä‘áº·t mÃ´ hÃ¬nh thá»§ cÃ´ng:")
            print("   ollama pull llama3.2")
            success = False
    
    print("\n" + "=" * 40)
    
    if success:
        print("âœ… Setup hoÃ n táº¥t! Báº¡n cÃ³ thá»ƒ cháº¡y:")
        print("   Streamlit: streamlit run text2cypher_demo.py")
        print("   Console: python console_demo.py")
    else:
        print("âŒ Setup chÆ°a hoÃ n táº¥t. Vui lÃ²ng xem hÆ°á»›ng dáº«n á»Ÿ trÃªn.")
        sys.exit(1)

if __name__ == "__main__":
    main() 